{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T15:09:47.792517Z",
     "start_time": "2025-11-26T15:09:42.429413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline, set_seed\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel"
   ],
   "id": "863b1bd71062c26b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dangth2004/Programming/Natural-Language-Processing/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-11-26 22:09:45.466549: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Khôi phục Masked Token (Masked Language Modeling)",
   "id": "f0080e0f5f072529"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T15:09:47.800219Z",
     "start_time": "2025-11-26T15:09:47.797434Z"
    }
   },
   "source": [
    "def fill_mask():\n",
    "    print(\"--- BÀI 1: Masked Language Modeling ---\")\n",
    "\n",
    "    # Tải pipeline \"fill-mask\"\n",
    "    mask_filler = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
    "\n",
    "    # Câu đầu vào\n",
    "    input_sentence = \"Hanoi is the [MASK] of Vietnam.\"\n",
    "\n",
    "    # Dự đoán\n",
    "    predictions = mask_filler(input_sentence, top_k=5)\n",
    "\n",
    "    print(f\"Câu gốc: {input_sentence}\")\n",
    "    for i, pred in enumerate(predictions, 1):\n",
    "        print(f\"{i}. Từ dự đoán: '{pred['token_str']}' | Độ tin cậy: {pred['score']:.4f}\")\n",
    "        print(f\"   -> Câu: {pred['sequence']}\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T15:10:03.594128Z",
     "start_time": "2025-11-26T15:09:47.849498Z"
    }
   },
   "cell_type": "code",
   "source": "fill_mask()",
   "id": "22ebfb2971406bd1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- BÀI 1: Masked Language Modeling ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Câu gốc: Hanoi is the [MASK] of Vietnam.\n",
      "1. Từ dự đoán: 'capital' | Độ tin cậy: 0.9991\n",
      "   -> Câu: hanoi is the capital of vietnam.\n",
      "2. Từ dự đoán: 'center' | Độ tin cậy: 0.0001\n",
      "   -> Câu: hanoi is the center of vietnam.\n",
      "3. Từ dự đoán: 'birthplace' | Độ tin cậy: 0.0001\n",
      "   -> Câu: hanoi is the birthplace of vietnam.\n",
      "4. Từ dự đoán: 'headquarters' | Độ tin cậy: 0.0001\n",
      "   -> Câu: hanoi is the headquarters of vietnam.\n",
      "5. Từ dự đoán: 'city' | Độ tin cậy: 0.0001\n",
      "   -> Câu: hanoi is the city of vietnam.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dự đoán từ tiếp theo (Next Token Prediction)",
   "id": "48b3ceb389fef216"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T15:10:03.646084Z",
     "start_time": "2025-11-26T15:10:03.643610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def text_generation():\n",
    "    print(\"\\n--- BÀI 2: Text Generation ---\")\n",
    "\n",
    "    # Tải pipeline \"text-generation\", sử dụng gpt2\n",
    "    generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "    prompt = \"The best thing about learning NLP is\"\n",
    "    set_seed(42)\n",
    "\n",
    "    # Sinh văn bản\n",
    "    output = generator(prompt, max_length=50, num_return_sequences=1, truncation=True)\n",
    "\n",
    "    print(f\"Prompt: '{prompt}'\")\n",
    "    print(\"-\" * 30)\n",
    "    print(output[0]['generated_text'])"
   ],
   "id": "1ec24e1fa91596ff",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T15:10:24.258744Z",
     "start_time": "2025-11-26T15:10:03.692476Z"
    }
   },
   "cell_type": "code",
   "source": "text_generation()",
   "id": "adc089e50da46b27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- BÀI 2: Text Generation ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: 'The best thing about learning NLP is'\n",
      "------------------------------\n",
      "The best thing about learning NLP is that you learn to learn something, and you learn it through hard work and hard work. It's not like you learn all at once, but you learn at what is most important.\n",
      "\n",
      "If you want to learn more, there are a lot of books out there that are written about NLP, and I think that's why they make sense. But at the same time, there are many books that have been written about NLP that people have done that have actually been successful.\n",
      "\n",
      "JUAN GONZÁLEZ: Well, this is a little bit of an aside. On a personal note, I'm really curious to know what the people who have been on the frontlines of NLP are doing right now. I know there's an organization called the NLP Project, and they're making a lot of changes going forward, and I'm curious about how they're doing with the NLP Project.\n",
      "\n",
      "So, the NLP Project is a group of people who are doing about two things right now. One is trying to get the word out about NLP in the press. The other is trying to get the word out about the NLP Project, and then building up to a broader audience. So, I guess, they\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tính toán Vector biểu diễn của câu (Sentence Representation)",
   "id": "214b4d932cb94095"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T15:10:24.321647Z",
     "start_time": "2025-11-26T15:10:24.317153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sentence_embedding():\n",
    "    print(\"\\n--- BÀI 3: Sentence Representation (Mean Pooling) ---\")\n",
    "\n",
    "    # Chọn mô hình và tokenizer\n",
    "    model_name = \"bert-base-uncased\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "    # Câu đầu vào\n",
    "    sentences = [\"This is a sample sentence\"]\n",
    "    # Tokenize\n",
    "    inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "    # Shape sẽ là [1, 7] (1 câu, 7 tokens bao gồm [CLS] và [SEP])\n",
    "    print(\"Input IDs shape:\", inputs['input_ids'].shape)\n",
    "\n",
    "    # Đưa qua mô hình (Forward pass)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Shape: (batch_size, sequence_length, hidden_size) -> (1, 7, 768)\n",
    "    last_hidden_state = outputs.last_hidden_state\n",
    "\n",
    "    # Thực hiện Mean Pooling\n",
    "    # Tính trung bình vector của các token, nhưng bỏ qua token đệm (padding)\n",
    "    attention_mask = inputs['attention_mask']\n",
    "\n",
    "    # Mở rộng mask để khớp kích thước với hidden state\n",
    "    mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "\n",
    "    # Tính tổng các vector (chỉ tính những token có mask = 1)\n",
    "    sum_embeddings = torch.sum(last_hidden_state * mask_expanded, 1)\n",
    "\n",
    "    # Tính tổng số lượng token thực (tránh chia cho 0 bằng cách dùng clamp)\n",
    "    sum_mask = torch.clamp(mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "    # Phép chia để lấy trung bình\n",
    "    sentence_embedding = sum_embeddings / sum_mask\n",
    "\n",
    "    print(\"Kích thước vector biểu diễn câu:\", sentence_embedding.shape)\n",
    "    print(\"5 giá trị đầu tiên của vector:\", sentence_embedding[0][:5])"
   ],
   "id": "f9d904320516cc1c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T15:10:26.378134Z",
     "start_time": "2025-11-26T15:10:24.366358Z"
    }
   },
   "cell_type": "code",
   "source": "sentence_embedding()",
   "id": "82292c8c5ad588d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- BÀI 3: Sentence Representation (Mean Pooling) ---\n",
      "Input IDs shape: torch.Size([1, 7])\n",
      "Kích thước vector biểu diễn câu: torch.Size([1, 768])\n",
      "5 giá trị đầu tiên của vector: tensor([-0.2424, -0.3832, -0.0138, -0.2991, -0.2145])\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
