{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b94c2136eb0b9b40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:32:09.083745Z",
     "start_time": "2025-11-25T19:32:07.455895Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "721686a34769c6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số câu tập Train: 12544\n",
      "Ví dụ câu đầu tiên: [('Al', 'PROPN'), ('-', 'PUNCT'), ('Zaman', 'PROPN'), (':', 'PUNCT'), ('American', 'ADJ')]...\n"
     ]
    }
   ],
   "source": [
    "# Định nghĩa các hằng số\n",
    "PAD_TOKEN = \"<PAD>\"\n",
    "UNK_TOKEN = \"<UNK>\"\n",
    "PAD_IDX = 0  # Chỉ số cho padding\n",
    "UNK_IDX = 1  # Chỉ số cho UNK\n",
    "\n",
    "\n",
    "def load_conllu(file_path):\n",
    "    \"\"\"Đọc dữ liệu từ file .conllu, trả về danh sách các câu.\"\"\"\n",
    "    sentences = []\n",
    "    current_sentence = []\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                # Dòng trống -> kết thúc câu\n",
    "                if current_sentence:\n",
    "                    sentences.append(current_sentence)\n",
    "                    current_sentence = []\n",
    "            elif not line.startswith('#'):\n",
    "                parts = line.split('\\t')\n",
    "                if parts and parts[0].isdigit():  # Đảm bảo là dòng chứa token (parts[0] là ID)\n",
    "                    word = parts[1]\n",
    "                    upos_tag = parts[3]\n",
    "                    current_sentence.append((word, upos_tag))\n",
    "\n",
    "    if current_sentence:\n",
    "        sentences.append(current_sentence)\n",
    "\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# Tải Dữ liệu\n",
    "train_data = load_conllu('/home/dangth2004/Programming/Natural-Language-Processing/data/UD_English-EWT/en_ewt-ud-train.conllu')\n",
    "dev_data = load_conllu('/home/dangth2004/Programming/Natural-Language-Processing/data/UD_English-EWT/en_ewt-ud-dev.conllu')\n",
    "\n",
    "print(f\"Số câu tập Train: {len(train_data)}\")\n",
    "print(f\"Ví dụ câu đầu tiên: {train_data[0][:5]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83cc32892c31657b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T13:12:38.668375Z",
     "start_time": "2025-11-18T13:12:38.601103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước Từ điển Từ (Word Vocab): 19675\n",
      "Kích thước Từ điển Nhãn (Tag Vocab): 18\n"
     ]
    }
   ],
   "source": [
    "def build_vocab(data):\n",
    "    \"\"\"Xây dựng từ điển word_to_ix và tag_to_ix.\"\"\"\n",
    "    word_to_ix = {PAD_TOKEN: PAD_IDX, UNK_TOKEN: UNK_IDX}\n",
    "    tag_to_ix = {PAD_TOKEN: PAD_IDX}  # Padding tag cũng dùng 0\n",
    "\n",
    "    all_words = set()\n",
    "    all_tags = set()\n",
    "    for sentence in data:\n",
    "        for word, tag in sentence:\n",
    "            all_words.add(word)\n",
    "            all_tags.add(tag)\n",
    "\n",
    "    for word in sorted(list(all_words)):\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "\n",
    "    for tag in sorted(list(all_tags)):\n",
    "        if tag not in tag_to_ix:\n",
    "            tag_to_ix[tag] = len(tag_to_ix)\n",
    "\n",
    "    return word_to_ix, tag_to_ix\n",
    "\n",
    "\n",
    "word_to_ix, tag_to_ix = build_vocab(train_data)\n",
    "ix_to_tag = {v: k for k, v in tag_to_ix.items()}\n",
    "\n",
    "print(f\"Kích thước Từ điển Từ (Word Vocab): {len(word_to_ix)}\")\n",
    "print(f\"Kích thước Từ điển Nhãn (Tag Vocab): {len(tag_to_ix)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b0153f5d12d674d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T13:12:41.171204Z",
     "start_time": "2025-11-18T13:12:41.166406Z"
    }
   },
   "outputs": [],
   "source": [
    "class POSDataset(Dataset):\n",
    "    def __init__(self, data, word_to_ix, tag_to_ix):\n",
    "        self.data = data\n",
    "        self.word_to_ix = word_to_ix\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.data[idx]\n",
    "\n",
    "        word_indices = [self.word_to_ix.get(word, UNK_IDX) for word, tag in sentence]\n",
    "        tag_indices = [self.tag_to_ix[tag] for word, tag in sentence]\n",
    "\n",
    "        return torch.tensor(word_indices, dtype=torch.long), torch.tensor(tag_indices, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72adadc4fad3394a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T13:12:42.453234Z",
     "start_time": "2025-11-18T13:12:42.447538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Số lượng batch trong Train Loader: 392\n"
     ]
    }
   ],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Hàm đệm (pad) các câu và nhãn trong cùng một batch.\n",
    "    Sử dụng torch.nn.utils.rnn.pad_sequence.\n",
    "    \"\"\"\n",
    "    # Tách X (sentence_indices) và Y (tag_indices)\n",
    "    sentences, tags = zip(*batch)\n",
    "\n",
    "    # Đệm các tensor X (sentences) và Y (tags)\n",
    "    # padding_value=PAD_IDX (0)\n",
    "    sentences_padded = nn.utils.rnn.pad_sequence(sentences, batch_first=True, padding_value=PAD_IDX)\n",
    "    tags_padded = nn.utils.rnn.pad_sequence(tags, batch_first=True, padding_value=PAD_IDX)\n",
    "\n",
    "    return sentences_padded, tags_padded\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = POSDataset(train_data, word_to_ix, tag_to_ix)\n",
    "dev_dataset = POSDataset(dev_data, word_to_ix, tag_to_ix)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "print(f\"\\nSố lượng batch trong Train Loader: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e52e66c99fb492d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T13:12:43.969573Z",
     "start_time": "2025-11-18T13:12:43.964364Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleRNNForTokenClassification(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(SimpleRNNForTokenClassification, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=embedding_dim,\n",
    "            padding_idx=PAD_IDX  # PyTorch sẽ bỏ qua chỉ số này khi tính embedding\n",
    "        )\n",
    "\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            batch_first=True  # Input có dạng (batch_size, seq_len, features)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        rnn_output, hidden_state = self.rnn(embedded)\n",
    "        batch_size, seq_len, hidden_dim = rnn_output.shape\n",
    "\n",
    "        rnn_output_reshaped = rnn_output.reshape(-1, hidden_dim)\n",
    "        prediction = self.fc(rnn_output_reshaped)\n",
    "\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e88814e564ba730",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T13:12:46.332936Z",
     "start_time": "2025-11-18T13:12:45.319028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleRNNForTokenClassification(\n",
      "  (embedding): Embedding(19675, 100, padding_idx=0)\n",
      "  (rnn): RNN(100, 128, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=18, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Config\n",
    "VOCAB_SIZE = len(word_to_ix)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = len(tag_to_ix)\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "# Khởi tạo mô hình và device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SimpleRNNForTokenClassification(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Sử dụng PAD_IDX (0) để CrossEntropyLoss bỏ qua các token đệm\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX).to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a03617c02ca59ebf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T13:12:47.456836Z",
     "start_time": "2025-11-18T13:12:47.453769Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, device):\n",
    "    \"\"\"Tính độ chính xác trên tập dữ liệu dev/test.\"\"\"\n",
    "    model.eval()\n",
    "    total_acc = 0\n",
    "\n",
    "    with torch.no_grad():  # Tắt tính toán gradient\n",
    "        for X_batch, y_batch in data_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            predictions = model(X_batch)\n",
    "            total_acc += calculate_accuracy(predictions.cpu(), y_batch.cpu())\n",
    "\n",
    "    return total_acc / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4e5e5d5913ed4fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T13:14:07.850183Z",
     "start_time": "2025-11-18T13:12:48.341925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Train Loss: 1.125 | Train Acc: 0.658 | Dev Acc: 0.747 | Training time: 1.37s\n",
      "Epoch: 02 | Train Loss: 0.623 | Train Acc: 0.802 | Dev Acc: 0.801 | Training time: 1.13s\n",
      "Epoch: 03 | Train Loss: 0.468 | Train Acc: 0.851 | Dev Acc: 0.825 | Training time: 1.13s\n",
      "Epoch: 04 | Train Loss: 0.371 | Train Acc: 0.882 | Dev Acc: 0.839 | Training time: 1.11s\n",
      "Epoch: 05 | Train Loss: 0.303 | Train Acc: 0.903 | Dev Acc: 0.848 | Training time: 1.06s\n",
      "Epoch: 06 | Train Loss: 0.252 | Train Acc: 0.920 | Dev Acc: 0.854 | Training time: 1.11s\n",
      "Epoch: 07 | Train Loss: 0.211 | Train Acc: 0.933 | Dev Acc: 0.856 | Training time: 1.10s\n",
      "Epoch: 08 | Train Loss: 0.178 | Train Acc: 0.943 | Dev Acc: 0.855 | Training time: 1.09s\n",
      "Epoch: 09 | Train Loss: 0.150 | Train Acc: 0.952 | Dev Acc: 0.857 | Training time: 1.16s\n",
      "Epoch: 10 | Train Loss: 0.128 | Train Acc: 0.960 | Dev Acc: 0.860 | Training time: 1.14s\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(y_pred, y_true):\n",
    "    \"\"\"Tính độ chính xác, bỏ qua các token đệm.\"\"\"\n",
    "    y_true_flat = y_true.view(-1)\n",
    "    max_preds = y_pred.argmax(dim=1)\n",
    "\n",
    "    # Tạo mask cho các token không phải PAD\n",
    "    non_pad_elements = (y_true_flat != PAD_IDX).nonzero(as_tuple=False)\n",
    "\n",
    "    # Chỉ tính toán trên các phần tử không phải PAD\n",
    "    correct = (max_preds[non_pad_elements] == y_true_flat[non_pad_elements]).sum()\n",
    "    total = non_pad_elements.size(0)\n",
    "\n",
    "    return correct.item() / total if total > 0 else 0.0\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        # Chuyển dữ liệu sang device\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(X_batch)\n",
    "        loss = criterion(predictions, y_batch.view(-1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += calculate_accuracy(predictions.detach().cpu(), y_batch.detach().cpu())\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "    train_time = end_time - start_time\n",
    "\n",
    "    avg_train_loss = epoch_loss / len(train_loader)\n",
    "    avg_train_acc = epoch_acc / len(train_loader)\n",
    "    avg_dev_acc = evaluate(model, dev_loader, device)\n",
    "\n",
    "    print(\n",
    "        f'Epoch: {epoch + 1:02} | Train Loss: {avg_train_loss:.3f} | Train Acc: {avg_train_acc:.3f} | Dev Acc: {avg_dev_acc:.3f} | Training time: {train_time:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ec9d345afb2cf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T13:15:01.190393Z",
     "start_time": "2025-11-18T13:15:01.185132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PRON', 'VERB', 'ADJ', 'NOUN', 'NOUN']\n"
     ]
    }
   ],
   "source": [
    "def predict_sentence(sentence_str, model, word_to_ix, ix_to_tag, device):\n",
    "    \"\"\"Nhận vào câu dạng chuỗi, trả về (từ, nhãn dự đoán).\"\"\"\n",
    "    model.eval()\n",
    "    tokens = sentence_str.lower().split()\n",
    "    indices = [word_to_ix.get(token, UNK_IDX) for token in tokens]\n",
    "    input_tensor = torch.tensor([indices], dtype=torch.long).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions = model(input_tensor)  # (seq_len, output_dim) vì batch_size=1\n",
    "        predicted_tag_indices = predictions.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "    # Chuyển chỉ số thành nhãn\n",
    "    predicted_tags = [ix_to_tag[idx] for idx in predicted_tag_indices]\n",
    "    print(predicted_tags)\n",
    "    return list(zip(tokens, predicted_tags))\n",
    "\n",
    "\n",
    "sentence = \"i love natural language processing\"\n",
    "prediction_result = predict_sentence(sentence, model, word_to_ix, ix_to_tag, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
